FLASK_APP=main.py
LLM_API_KEY=
LLM_BASE_URL=https://openrouter.ai/api/v1
ENABLE_LOCAL_TELEMETRY=#true <-- uncomment to enable logs for debugging
MODEL_NAME=meta-llama/llama-3.2-3b-instruct:nitro
# llama-3.2-3b-instruct:nitro should be both extremely cheap and should be fast enough to keep up with chat
# Some other models you can try out:
# MODEL_NAME=google/gemini-2.0-flash-lite-001
# MODEL_NAME=google/gemini-2.0-flash-lite-preview-02-05:free
# MODEL_NAME=meta-llama/llama-3.2-3b-instruct:free
# MODEL_NAME=meta-llama/llama-3.2-1b-instruct:free
# MODEL_NAME=google/gemma-3-1b-it:free
# MODEL_NAME=google/gemini-2.0-flash-exp:free